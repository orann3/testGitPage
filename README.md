# [RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation](https://x-humanoid-robomind.github.io/)

[![License](https://img.shields.io/badge/License-Apache_2.0-yellow.svg)](https://opensource.org/licenses/Apache-2.0)
[![Project Page](https://img.shields.io/badge/Project%20Page-RoboMIND-blue.svg)](https://x-humanoid-robomind.github.io/)
[![arXiv](https://badgen.net/badge/icon/arXiv?icon=awesome&label&color=red&style=flat-square)](https://arxiv.org/abs/2412.13877)
[![Dataset](https://img.shields.io/badge/Dataset-TBU-000000.svg)](https://zitd5je6f7j.feishu.cn/share/base/form/shrcnOF6Ww4BuRWWtxljfs0aQqh)
[![QQç¾¤](https://img.shields.io/badge/QQç¾¤-XXXXXXXX-orange.svg)](https://zitd5je6f7j.feishu.cn/share/base/form/shrcnOF6Ww4BuRWWtxljfs0aQqh)


## ğŸ“ æ•°æ®è¯´æ˜ ğŸ“
æ„å»ºé«˜è´¨é‡çš„æœºå™¨äººè®­ç»ƒæ•°æ®é›†å¯¹å¼€å‘å…·æœ‰è‰¯å¥½æ³›åŒ–èƒ½åŠ›çš„ç«¯åˆ°ç«¯å…·èº«æ™ºèƒ½å¤§æ¨¡å‹è‡³å…³é‡è¦ã€‚ç†æƒ³çš„æ•°æ®é›†åº”æ¶µç›–å¤šæ ·åŒ–çš„åœºæ™¯ã€ä»»åŠ¡ç±»å‹å’Œæœºå™¨äººå¹³å°ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä¸åŒç¯å¢ƒå¹¶å¯é æ‰§è¡Œå„ç±»ä»»åŠ¡ã€‚æœ¬å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€çœŸå®çš„æœºå™¨äººå­¦ä¹ æ•°æ®é›†ï¼Œè®°å½•æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­æ‰§è¡Œé•¿ç¨‹ä»»åŠ¡æ—¶çš„äº¤äº’æ•°æ®ï¼Œä»è€Œæ”¯æŒè®­ç»ƒå‡ºå…·æœ‰é€šç”¨æ“ä½œèƒ½åŠ›çš„æ™ºèƒ½æ¨¡å‹ã€‚

æœ¬æ•°æ®é›†çš„éƒ¨åˆ†ç›®å½•ç»“æ„ç¤ºä¾‹å¦‚ä¸‹ï¼Œå±•ç¤ºäº†Frankaæœºå™¨äººä¸‹å•ä¸ªä»»åŠ¡çš„2æ¡è®­ç»ƒè½¨è¿¹å’Œ2æ¡éªŒè¯è½¨è¿¹ï¼š
```
.
|-- h5_franka_1rgb
|   |-- bread_in_basket
|   |   `-- success_episodes
|   |       |-- train
|   |       |   |-- 1014_144236
|   |       |   |   `-- data
|   |       |   |       `-- trajectory.hdf5
|   |       |   |-- 1014_144602
|   |       |   |   `-- data
|   |       |   |       `-- trajectory.hdf5
|   |       |-- val
|   |       |   |-- 1014_144642
|   |       |   |   `-- data
|   |       |   |       `-- trajectory.hdf5
|   |       |   |-- 1014_151731
|   |       |   |   `-- data
|   |       |   |       `-- trajectory.hdf5
| -- h5_franka_3rgb
| -- h5_tiangong_1rg
| -- h5_ur_1rgb
| -- h5_songling_3rg
| -- h5_simulation
```

## ğŸ’¾ æ•°æ®åˆ†å¸ƒ ğŸ’¾
<img src="./static/images/piechart.png" border=0 width=100%>

### ğŸ¤– æœºå™¨äººå¹³å°æ„æˆ ğŸ¤–
RoboMINDæ•°æ®é›†æ±‡é›†äº†å¤šç§æœºå™¨äººå¹³å°çš„æ“ä½œæ•°æ®ï¼ŒåŒ…æ‹¬19,222æ¡Franka Emika Pandaå•è‡‚æœºå™¨äººè½¨è¿¹ã€9,686æ¡"å¤©å·¥"äººå½¢æœºå™¨äººè½¨è¿¹ã€8,030æ¡AgileX Cobot Magic V2.0åŒè‡‚æœºå™¨äººè½¨è¿¹ã€6,911æ¡UR-5eå•è‡‚æœºå™¨äººè½¨è¿¹ï¼Œä»¥åŠ11,783æ¡åœ¨ä»¿çœŸç¯å¢ƒä¸­é‡‡é›†çš„Frankaæœºæ¢°è‡‚æ•°æ®ã€‚å…¶ä¸­ï¼Œè‡ªç ”çš„"å¤©å·¥"äººå½¢æœºå™¨äººè´¡çŒ®äº†17.4%çš„æ•°æ®é‡ï¼Œæä¾›äº†å¤§é‡éœ€è¦é«˜åº¦åè°ƒèƒ½åŠ›çš„åŒè‡‚æ“ä½œä»»åŠ¡ã€‚

### ğŸ” è½¨è¿¹æ—¶é•¿åˆ†å¸ƒ ğŸ”
ä»è½¨è¿¹é•¿åº¦æ¥çœ‹ï¼Œä¸åŒæœºå™¨äººå¹³å°å‘ˆç°å‡ºç‹¬ç‰¹çš„åˆ†å¸ƒç‰¹å¾ã€‚Frankaå’ŒURæœºå™¨äººçš„ä»»åŠ¡é€šå¸¸å…·æœ‰è¾ƒçŸ­çš„è½¨è¿¹ï¼Œæ—¶é—´æ­¥æ•°å°‘äº200æ­¥ï¼Œè¿™ç±»æ•°æ®ç‰¹åˆ«é€‚åˆç”¨äºè®­ç»ƒåŸºç¡€æ“ä½œæŠ€èƒ½ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ"å¤©å·¥"å’ŒAgileXæœºå™¨äººçš„ä»»åŠ¡è½¨è¿¹æ™®éè¾ƒé•¿ï¼Œè¶…è¿‡500ä¸ªæ—¶é—´æ­¥ï¼Œæ›´é€‚åˆç”¨äºè®­ç»ƒé•¿æ—¶é—´è·¨åº¦çš„ä»»åŠ¡å’Œå¤æ‚æŠ€èƒ½ç»„åˆã€‚

### ğŸš€ ä»»åŠ¡ç±»å‹åˆ’åˆ† ğŸš€
åŸºäºè‡ªç„¶è¯­è¨€æè¿°ï¼Œå¹¶è€ƒè™‘ç‰©å“å¤§å°ã€ä½¿ç”¨åœºæ™¯å’Œæ“ä½œæŠ€èƒ½ç­‰å› ç´ ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†ä¸­çš„ä»»åŠ¡åˆ†ä¸ºåŸºç¡€æŠ€èƒ½ã€ç²¾å‡†æ“ä½œã€åœºæ™¯ç†è§£ã€æŸœä½“æ“ä½œå’Œåä½œä»»åŠ¡äº”å¤§ç±»ã€‚é™¤äº†åŸºç¡€æ“ä½œä»»åŠ¡å¤–ï¼Œæ•°æ®é›†è¿˜åŒ…å«äº†å¤§é‡å¤æ‚ä»»åŠ¡ï¼Œä¸ºè®­ç»ƒé€šç”¨æœºå™¨äººç­–ç•¥æä¾›äº†ä¸°å¯Œçš„æ•°æ®æ”¯æŒã€‚

### ğŸ’ª ç‰©å“å¤šæ ·æ€§ ğŸ’ª
æ•´ä¸ªæ•°æ®é›†åŒ…å«äº†61ç§ä¸åŒçš„ç‰©å“ç±»åˆ«ï¼Œå…·ä½“å¦‚ä¸‹æ‰€ç¤ºã€‚å¯ä»¥çœ‹å‡ºï¼Œåœ¨å¨æˆ¿åœºæ™¯ä¸­ï¼Œæ•°æ®é›†ä¸ä»…åŒ…å«äº†å¸¸è§çš„é£Ÿç‰©ï¼Œå¦‚è‰è“ã€é¸¡è›‹ã€é¦™è•‰å’Œæ¢¨å­ç­‰ï¼Œä¹ŸåŒ…æ‹¬äº†å¤æ‚çš„å¯è°ƒèŠ‚ç‰©ä½“ï¼Œå¦‚çƒ¤ç®±å’Œé¢åŒ…æœºã€‚åœ¨å®¶åº­åœºæ™¯ä¸­ï¼Œæ•°æ®é›†æ—¢åŒ…æ‹¬äº†åˆšæ€§ç‰©ä½“ï¼Œå¦‚ç½‘çƒï¼Œä¹ŸåŒ…æ‹¬äº†å¯å˜å½¢ç‰©ä½“ï¼Œå¦‚ç©å…·ã€‚åŠå…¬å’Œå·¥ä¸šåœºæ™¯åˆ™åŒ…å«äº†éœ€è¦ç²¾ç¡®æ§åˆ¶çš„å°ç‰©ä½“ï¼Œå¦‚ç”µæ± å’Œé½¿è½®ã€‚è¿™æ ·å¤šæ ·åŒ–çš„ç‰©ä½“ç§ç±»ä¸ä»…å¢åŠ äº†æ•°æ®é›†çš„å¤æ‚æ€§ï¼Œä¹Ÿæœ‰åŠ©äºè®­ç»ƒèƒ½å¤Ÿåœ¨å„ç§ç¯å¢ƒä¸‹æ‰§è¡Œæ“ä½œçš„é€šç”¨æ“æ§ç­–ç•¥ã€‚

// <img src="./static/images/Distribution.png" border=0 width=80% text-align=center>

<div style="text-align: center; margin: 0 auto; width: 80%;">
  <img src="./static/images/Distribution.png" alt="object_type_distribution" style="width: 80%; height: auto;">
</div>

## ğŸ“Š æ•°æ®ä½¿ç”¨ ğŸ“Š

```
!pip install numpy
!pip install opencv-python
!pip install h5py
!pip install imageio
```

``` 
import numpy as np
import os
import cv2
import copy
import argparse
import imageio
import h5py
import cv2
from collections import defaultdict
from IPython.display import Image, display
import argparse
```

```
RESOLUTION = (128, 128)
```

```
class ReadH5Files():
    def __init__(self, robot_infor):
        self.camera_names = robot_infor['camera_names']
        self.camera_sensors = robot_infor['camera_sensors']
        self.arms = robot_infor['arms']
        self.robot_infor = robot_infor['controls']

    def decoder_image(self, camera_rgb_images, camera_depth_images):
        if type(camera_rgb_images[0]) is np.uint8:
            rgb = cv2.imdecode(camera_rgb_images, cv2.IMREAD_COLOR)
            if camera_depth_images is not None:
                depth_array = np.frombuffer(camera_depth_images, dtype=np.uint8)
                depth = cv2.imdecode(depth_array, cv2.IMREAD_UNCHANGED)
            else:
                depth = np.asarray([])
            return rgb, depth
        else:
            rgb_images = []
            depth_images = []
            for idx, camera_rgb_image in enumerate(camera_rgb_images):
                camera_rgb_image = np.array(camera_rgb_image)
                rgb = cv2.imdecode(camera_rgb_image, cv2.IMREAD_COLOR)
                if camera_depth_images is not None:
                    depth_array = np.frombuffer(camera_depth_images[idx], dtype=np.uint8)
                    depth = cv2.imdecode(depth_array, cv2.IMREAD_UNCHANGED)
                else:
                    depth = np.asarray([])
                rgb_images.append(rgb)
                depth_images.append(depth)
            rgb_images = np.asarray(rgb_images)
            depth_images = np.asarray(depth_images)
            return rgb_images, depth_images

    def execute(self, file_path, camera_frame=None, control_frame=None):
        with h5py.File(file_path, 'r') as f:
            is_sim = f.attrs['sim']
            is_compress = f.attrs['compress']
            is_compress = True
            image_dict = defaultdict(dict)
            for cam_name in self.camera_names:
                if is_compress:
                    if camera_frame is not None:
                        if len(self.camera_sensors) >= 2:
                            decode_rgb, decode_depth = self.decoder_image(
                                camera_rgb_images=f['observations'][self.camera_sensors[0]][cam_name][camera_frame],
                                    camera_depth_images=f['observations'][self.camera_sensors[1]][cam_name][camera_frame])
                        else:
                            decode_rgb, decode_depth = self.decoder_image(
                                camera_rgb_images=f['observations'][self.camera_sensors[0]][cam_name][camera_frame],
                                camera_depth_images=None)
                    else:
                        if len(self.camera_sensors) >= 2:
                            rgb_images = f['observations'][self.camera_sensors[0]][cam_name][:]
                            depth_images = f['observations'][self.camera_sensors[1]][cam_name][:]
                        else:
                            rgb_images = f['observations'][self.camera_sensors[0]][cam_name][:]
                            depth_images = None
                        decode_rgb, decode_depth = self.decoder_image(camera_rgb_images=rgb_images,camera_depth_images=depth_images)
                    
                    image_dict[self.camera_sensors[0]][cam_name] = decode_rgb
                    if len(self.camera_sensors) >= 2:
                        image_dict[self.camera_sensors[1]][cam_name] = decode_depth

                else:
                    if camera_frame:
                        image_dict[self.camera_sensors[0]][cam_name] = f[
                            'observations'][self.camera_sensors[0]][cam_name][camera_frame]
                        image_dict[self.camera_sensors[1]][cam_name] = f[
                            'observations'][self.camera_sensors[1]][cam_name][camera_frame]
                    else:
                        image_dict[self.camera_sensors[0]][cam_name] = f[
                           'observations'][self.camera_sensors[0]][cam_name][:]


            control_dict = defaultdict(dict)
            for arm_name in self.arms:
                for control in self.robot_infor:
                    if control_frame:
                        control_dict[arm_name][control] = f[arm_name][control][control_frame]
                    else:
                        control_dict[arm_name][control] = f[arm_name][control][:]
            base_dict = defaultdict(dict)
        return image_dict[self.camera_sensors[0]], control_dict, base_dict, is_sim, is_compress
```

```
def convert_dataset_image(robot_infor, resolution=RESOLUTION, dataset_dir="realworld_data", env_names=None, episode_num_pertask=5000):
    read_h5files = ReadH5Files(robot_infor)

    for env_name in env_names:
        # åˆ›å»ºä¿å­˜å›¾åƒçš„æ–‡ä»¶å¤¹
        save_dir = f'saved_images/{env_name}'
        os.makedirs(save_dir, exist_ok=True)
        
        dataset_root = os.path.join(dataset_dir, env_name, 'success_episodes/train')
        cnt = 0
        for trajectory_id in sorted(os.listdir(dataset_root))[0:episode_num_pertask]:
            for file in os.listdir(os.path.join(dataset_root, trajectory_id, 'data')):
                if file.endswith('.hdf5'):
                    file_path = os.path.join(dataset_root, trajectory_id, 'data', file)
                    break
            print('executing ', cnt, 'th trajectory, file_path:', file_path)
            cnt += 1
            assert os.path.exists(file_path), f'{file_path} does not exist'
            image_dict, control_dict, base_dict, _, is_compress = read_h5files.execute(file_path)
            action_list = []
            for keys in control_dict.keys():
                control_list = []
                for control_key in control_dict[keys].keys():
                    control = control_dict[keys][control_key]
                    control_list.append(control)
                control = np.concatenate(control_list, axis=1)
                action_list.append(control)
            action = np.concatenate(action_list, axis=1)
            state = copy.deepcopy(action)
            
            action = action[1:]
            state = state[0:-1]
            for key in image_dict.keys():
                image_dict[key] = image_dict[key][0:-1]
            
            # Process images and create GIFs for each camera
            for cam_name in image_dict.keys():
                os.makedirs(os.path.join(save_dir, trajectory_id), exist_ok=True)
                gif_path = os.path.join(save_dir, trajectory_id, f'{cam_name}.gif')
                
                # Convert images to correct color format
                images = []
                for step in range(len(action)):
                    img = np.array(image_dict[cam_name][step])
                    # Convert BGR to RGB if necessary
                    if img.shape[-1] == 3:  # Check if image has 3 channels
                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    img = cv2.resize(img, resolution, interpolation=cv2.INTER_AREA)
                    images.append(img)
                
                imageio.mimsave(gif_path, images, duration=0.1)  # 10 FPS
                print(f"Saved GIF to {gif_path}")
                # Display the GIF in the notebook
                display(Image(filename=gif_path))
            return 
```

```
def main(args):
    env_name = args.env_name
    if args.embodiments == "h5_ur_1rgb":
        robot_infor = { 
            "camera_names": ['camera_top'], 
            "camera_sensors": ['rgb_images'],
            "arms": ['puppet'],
            "controls": ['joint_position', 'end_effector'],
            "resolution": RESOLUTION
        }
        env_name = "bread_on_table" if args.env_name is None else args.env_name
    elif args.embodiments == "h5_franka_3rgb":
        robot_infor = {
            "camera_names": ['camera_top', 'camera_left', 'camera_right'],
            "camera_sensors": ['rgb_images'],
            "arms": ['puppet'],
            "controls": ['joint_position', 'end_effector'],
            "resolution": RESOLUTION
        }
        # env_name = "place_in_fruit"
        env_name = "2024_09_20_close_cabinet" if args.env_name is None else args.env_name
    elif args.embodiments == "h5_franka_1rgb":
        robot_infor = {
            "camera_names": ['camera_top'],
            "camera_sensors": ['rgb_images'],
            "arms": ['puppet'],
            "controls": ['joint_position', 'end_effector'],
            "resolution": RESOLUTION
        }
        trajectory_id = '1014_144358'
        env_name = "bread_on_table" if args.env_name is None else args.env_name
    elif args.embodiments == "h5_tienkung_1rgb":
        robot_infor = {
            "camera_names": ['camera_top'],
            "camera_sensors": ['rgb_images'],
            "arms": ['puppet','master'],
            "controls": ['joint_position', 'end_effector'],
            "resolution": RESOLUTION
        }
        env_name = "place_button" if args.env_name is None else args.env_name
    elif args.embodiments == "h5_agilex_3rgb":
        robot_infor = {
            "camera_names": ['camera_front', 'camera_left_wrist', 'camera_right_wrist'],
            "camera_sensors": ['rgb_images'],
            "arms": ['puppet', 'master'],
            "controls":  ['end_effector_left', 'end_effector_right', 'joint_effort_left', 'joint_effort_right', 'joint_position_left', 'joint_position_right', 'joint_velocity_left', 'joint_velocity_right'],
            "resolution": RESOLUTION
        }
        env_name = "35_putcarrot" if args.env_name is None else args.env_name
    elif args.embodiments == "h5_simulation":
        robot_infor = {
            "camera_names":  ['camera_front_external', 'camera_handeye', 'camera_left_external', 'camera_right_external'],
            "camera_sensors": ['rgb_images'],
            "arms": ['franka'],
            "controls": ['end_effector', 'joint_effort', 'joint_position', 'joint_velocity'],
            "resolution": RESOLUTION
        }
        env_name = "open_and_close_01" if args.env_name is None else args.env_name
    else:
        raise ValueError(f"Invalid embodiment: {args.embodiments}")
    dataset_dir = os.path.join(args.dataset_path, args.embodiments)
    convert_dataset_image(robot_infor, resolution=RESOLUTION, dataset_dir=dataset_dir, env_names=[env_name], episode_num_pertask=5)
```

```
if __name__ == "__main__":
    args = argparse.ArgumentParser()
    args.add_argument("--embodiments", type=str, 
                     choices=["h5_franka_1rgb", "h5_franka_3rgb", "h5_tienkung_1rgb", "h5_ur_1rgb", "h5_agilex_3rgb", "h5_simulation"],
                     default="h5_ur_1rgb",
                     help="Choose the embodiment for data processing")
    args.add_argument("--dataset_path", type=str, default="/media/data/benchmark1_0")
    args.add_argument("--env_name", type=str, default=None)
    args = args.parse_args([
    '--embodiments', 'h5_ur_1rgb',
    '--dataset_path', '/media/data/benchmark1_0',
    '--env_name', 'bread_on_table'
])
    main(args)
```


## ğŸ“ Citation ğŸ“
If you find RoboMIND useful in your research, please consider citing:
```
@article{wu2024robomindbenchmarkmultiembodimentintelligence,
        title={RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation},
        author={Kun Wu and Chengkai Hou and Jiaming Liu and Zhengping Che and Xiaozhu Ju and Zhuqin Yang and Meng Li and Yinuo Zhao and Zhiyuan Xu and Guang Yang and Zhen Zhao and Guangyu Li and Zhao Jin and Lecheng Wang and Jilei Mao and Xinhua Wang and Shichao Fan and Ning Liu and Pei Ren and Qiang Zhang and Yaoxu Lyu and Mengzhen Liu and Jingyang He and Yulin Luo and Zeyu Gao and Chenxuan Li and Chenyang Gu and Yankai Fu and Di Wu and Xingyu Wang and Sixiang Chen and Zhenyu Wang and Pengju An and Siyuan Qian and Shanghang Zhang and Jian Tang},
        journal={arXiv preprint arXiv:2412.13877},
        year={2024}
      }
```



## å‚ä¸è®¨è®º
å¦‚æœæ‚¨å¯¹ RoboMIND æ„Ÿå…´è¶£ï¼Œæ¬¢è¿åŠ å…¥å¾®ä¿¡ç¾¤ï¼Œå‚ä¸è®¨è®ºã€‚

<img src="./static/images/piechart.png" border=0 width=50%>

